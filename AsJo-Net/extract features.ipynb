{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, dataloader\n",
    "StereoDataset = __datasets__[args.dataset]\n",
    "train_dataset = StereoDataset(args.datapath, args.trainlist, True)\n",
    "test_dataset = StereoDataset(args.datapath, args.testlist, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainImgLoader = DataLoader(train_dataset, args.batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "TestImgLoader = DataLoader(test_dataset, args.test_batch_size, shuffle=False, num_workers=4, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max disparity value: 99.39130401611328\n",
      "Min disparity value: 1.1745235919952393\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def read_pfm(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        color = None\n",
    "        width = None\n",
    "        height = None\n",
    "        scale = None\n",
    "        endian = None\n",
    "\n",
    "        header = file.readline().rstrip()\n",
    "        if header == b'PF':\n",
    "            color = True\n",
    "        elif header == b'Pf':\n",
    "            color = False\n",
    "        else:\n",
    "            raise Exception('Not a PFM file.')\n",
    "\n",
    "        dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('latin-1'))\n",
    "        if dim_match:\n",
    "            width, height = map(int, dim_match.groups())\n",
    "        else:\n",
    "            raise Exception('Malformed PFM header.')\n",
    "\n",
    "        scale = float(file.readline().rstrip().decode('latin-1'))\n",
    "        if scale < 0:  # little-endian\n",
    "            endian = '<'\n",
    "            scale = -scale\n",
    "        else:\n",
    "            endian = '>'  # big-endian\n",
    "\n",
    "        data = np.fromfile(file, endian + 'f')\n",
    "        shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "        data = np.reshape(data, shape)\n",
    "        data = np.flipud(data)\n",
    "        return data, scale\n",
    "\n",
    "# data, scale = read_pfm(r'C:\\Users\\Askil\\Documents\\SceneFlow\\sceneflow\\FlyingThings\\FlyingThings3D_subset\\train\\disparity\\left\\0000003.pfm')\n",
    "data, scale = read_pfm(r'C:\\Users\\Askil\\iCloudDrive\\Data Science\\data_science\\spesiale\\Sampler\\FlyingThings3D\\disparity\\0006.pfm')\n",
    "print(f\"Max disparity value: {data.max()}\")\n",
    "print(f\"Min disparity value: {data.min()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max disparity value: -1.1875\n",
      "Min disparity value: -137.4375\n"
     ]
    }
   ],
   "source": [
    "from datasets.data_io import pfm_imread\n",
    "import numpy as np\n",
    "\n",
    "data, scale = pfm_imread(r'C:\\Users\\Askil\\Documents\\SceneFlow\\sceneflow\\FlyingThings\\FlyingThings3D_subset\\train\\disparity\\left\\0000003.pfm')\n",
    "# data = np.ascontiguousarray(data, dtype=np.float32)\n",
    "print(f\"Max disparity value: {data.max()}\")\n",
    "print(f\"Min disparity value: {data.min()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -1.5625 ,   -1.5625 ,   -1.5625 , ...,   -1.375  ,   -1.375  ,\n",
       "          -1.375  ],\n",
       "       [  -1.5625 ,   -1.5625 ,   -1.5625 , ...,   -1.375  ,   -1.375  ,\n",
       "          -1.375  ],\n",
       "       [  -1.5625 ,   -1.5625 ,   -1.5625 , ...,   -1.375  ,   -1.375  ,\n",
       "          -1.375  ],\n",
       "       ...,\n",
       "       [ -24.6875 ,  -24.6875 ,  -24.6875 , ..., -100.125  , -100.25   ,\n",
       "        -100.40625],\n",
       "       [ -24.6875 ,  -24.6875 ,  -24.6875 , ..., -100.09375, -100.25   ,\n",
       "        -100.375  ],\n",
       "       [ -24.6875 ,  -24.6875 ,  -24.6875 , ..., -100.09375, -100.21875,\n",
       "        -100.34375]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Askil\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start at epoch 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "# import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "# from tensorboardX import SummaryWriter\n",
    "from datasets import __datasets__\n",
    "from models import __models__, model_loss_train, model_loss_test\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets.data_io import read_all_lines\n",
    "import torchinfo\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cudnn.benchmark = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    model: str = 'CGI_Stereo'\n",
    "    maxdisp: int = 192\n",
    "    dataset: str = 'sceneflow'\n",
    "    # datapath: str = \"/Users/askilfolgero/Documents/\"\n",
    "    datapath: str = r'C:\\Users\\Askil\\Documents\\SceneFlow'\n",
    "    trainlist: str = Path('sceneflow_train_flying_things.txt')\n",
    "    testlist: str =  Path('sceneflow_val_flying_things.txt')\n",
    "    lr: float = 0.001\n",
    "    batch_size: int = 1\n",
    "    test_batch_size: int = 1\n",
    "    epochs: int = 5\n",
    "    lrepochs: str = \"10,14,16,18:2\"\n",
    "    logdir: str = '.'\n",
    "    loadckpt: str = ''\n",
    "    resume: bool = False\n",
    "    seed: int = 1\n",
    "    summary_freq: int = 20\n",
    "    save_freq: int = 1\n",
    "\n",
    "args = Args()\n",
    "torch.manual_seed(args.seed)\n",
    "os.makedirs(args.logdir, exist_ok=True)\n",
    "\n",
    "# create summary logger\n",
    "# print(\"creating new summary file\")\n",
    "# logger = SummaryWriter(args.logdir)\n",
    "\n",
    "# model, optimizer\n",
    "model = __models__[args.model](args.maxdisp)\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "num_samples = 16\n",
    "StereoDataset = __datasets__[args.dataset]\n",
    "with open(\"temp_subset_filenames.txt\", \"w\") as f:\n",
    "    lines = read_all_lines(args.trainlist)\n",
    "    subsample = random.choices(lines, k = num_samples)\n",
    "    for sample in subsample:\n",
    "        f.write(sample)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "train_dataset = StereoDataset(args.datapath, \"temp_subset_filenames.txt\", True)\n",
    "test_dataset = StereoDataset(args.datapath, \"temp_subset_filenames.txt\", False)\n",
    "TrainImgLoader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "TestImgLoader = DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=4, drop_last=False)\n",
    "\n",
    "\n",
    "# load parameters\n",
    "start_epoch = 0\n",
    "if args.resume:\n",
    "    # find all checkpoints file and sort according to epoch id\n",
    "    all_saved_ckpts = [fn for fn in os.listdir(args.logdir) if fn.endswith(\".ckpt\")]\n",
    "    all_saved_ckpts = sorted(all_saved_ckpts, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "    # use the latest checkpoint file\n",
    "    loadckpt = os.path.join(args.logdir, all_saved_ckpts[-1])\n",
    "    print(f\"loading the lastest model in logdir: {loadckpt}\")\n",
    "    state_dict = torch.load(loadckpt)\n",
    "    model.load_state_dict(state_dict['model'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer'])\n",
    "    start_epoch = state_dict['epoch'] + 1\n",
    "\n",
    "elif args.loadckpt:\n",
    "    # load the checkpoint file specified by args.loadckpt\n",
    "    print(\"loading model {}\".format(args.loadckpt))\n",
    "    state_dict = torch.load(args.loadckpt)\n",
    "    model_dict = model.state_dict()\n",
    "    pre_dict = {k: v for k, v in state_dict['model'].items() if k in model_dict}\n",
    "    model_dict.update(pre_dict) \n",
    "    # model.load_state_dict(state_dict['model'])\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "print(f\"start at epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "# train one sample\n",
    "def train_sample(sample, compute_metrics=False):\n",
    "    model.train()\n",
    "    imgL        = sample['left'].to(device)\n",
    "    imgR        = sample['right'].to(device)\n",
    "    disp_gt     = sample['disparity'].to(device)\n",
    "    disp_gt_low = sample['disparity_low'].to(device)\n",
    "    print(f\"Max disparity value: {disp_gt.max()}\")\n",
    "    print(f\"Min disparity value: {disp_gt.min()}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    disp_ests = model(imgL, imgR)\n",
    "    mask      = (disp_gt < args.maxdisp) & (disp_gt > 0)\n",
    "    mask_low  = (disp_gt_low < args.maxdisp) & (disp_gt_low > 0)\n",
    "    masks     = [mask, mask_low]\n",
    "    disp_gts  = [disp_gt, disp_gt_low] \n",
    "    loss      = model_loss_train(disp_ests, disp_gts, masks)\n",
    "\n",
    "    scalar_outputs = {\"loss\": loss}\n",
    "    image_outputs = {\"disp_est\": disp_ests, \"disp_gt\": disp_gt, \"imgL\": imgL, \"imgR\": imgR}\n",
    "    \n",
    "    if compute_metrics:\n",
    "        with torch.no_grad():\n",
    "            # image_outputs[\"errormap\"] = [disp_error_image_func()(disp_est, disp_gt) for disp_est in [disp_ests[0]]]\n",
    "            scalar_outputs[\"D1\"]      = [D1_metric(disp_est, disp_gt, mask) for disp_est in [disp_ests[0]]]\n",
    "            scalar_outputs[\"EPE\"]     = [EPE_metric(disp_est, disp_gt, mask) for disp_est in [disp_ests[0]]]\n",
    "            # scalar_outputs[\"Thres1\"]  = [Thres_metric(disp_est, disp_gt, mask, 1.0) for disp_est in [disp_ests[0]]]\n",
    "            # scalar_outputs[\"Thres2\"]  = [Thres_metric(disp_est, disp_gt, mask, 2.0) for disp_est in [disp_ests[0]]]\n",
    "            # scalar_outputs[\"Thres3\"]  = [Thres_metric(disp_est, disp_gt, mask, 3.0) for disp_est in [disp_ests[0]]]\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return tensor2float(loss), tensor2float(scalar_outputs)\n",
    "\n",
    "\n",
    "# test one sample\n",
    "@make_nograd_func\n",
    "def test_sample(sample, compute_metrics=True):\n",
    "    model.eval()\n",
    "    imgL    = sample['right'].to(device)\n",
    "    imgR    = sample['left'].to(device)\n",
    "    disp_gt = sample['disparity'].to(device)\n",
    "\n",
    "    disp_ests = model(imgL, imgR)\n",
    "    mask      = (disp_gt < args.maxdisp) & (disp_gt > 0)\n",
    "    masks     = [mask]\n",
    "    disp_gts  = [disp_gt]\n",
    "    loss      = model_loss_test(disp_ests, disp_gts, masks)\n",
    "    print(loss)\n",
    "\n",
    "    scalar_outputs = {\"loss\": loss}\n",
    "    # image_outputs = {\"disp_est\": disp_ests, \"disp_gt\": disp_gt, \"imgL\": imgL, \"imgR\": imgR}\n",
    "\n",
    "    scalar_outputs[\"D1\"]     = [   D1_metric(disp_est, disp_gt, mask) for disp_est in disp_ests]\n",
    "    scalar_outputs[\"EPE\"]    = [  EPE_metric(disp_est, disp_gt, mask) for disp_est in disp_ests]\n",
    "    scalar_outputs[\"Thres1\"] = [Thres_metric(disp_est, disp_gt, mask, 1.0) for disp_est in disp_ests]\n",
    "    scalar_outputs[\"Thres2\"] = [Thres_metric(disp_est, disp_gt, mask, 2.0) for disp_est in disp_ests]\n",
    "    scalar_outputs[\"Thres3\"] = [Thres_metric(disp_est, disp_gt, mask, 3.0) for disp_est in disp_ests]\n",
    "\n",
    "    # if compute_metrics:\n",
    "    #     image_outputs[\"errormap\"] = [disp_error_image_func()(disp_est, disp_gt) for disp_est in disp_ests]\n",
    "\n",
    "    return tensor2float(loss), tensor2float(scalar_outputs)\n",
    "\n",
    "\n",
    "def train():\n",
    "    bestepoch = 0\n",
    "    error = 100\n",
    "    for epoch_idx in range(start_epoch, args.epochs):\n",
    "        adjust_learning_rate(optimizer, epoch_idx, args.lr, args.lrepochs)\n",
    "\n",
    "        # training\n",
    "        for batch_idx, sample in enumerate(TrainImgLoader):\n",
    "            global_step = len(TrainImgLoader) * epoch_idx + batch_idx\n",
    "            start_time = time.time()\n",
    "            do_summary = global_step % args.summary_freq == 0\n",
    "            loss, scalar_outputs = train_sample(sample, compute_metrics=do_summary)\n",
    "\n",
    "            # if do_summary:\n",
    "                # save_scalars(logger, 'train', scalar_outputs, global_step)\n",
    "                # save_images(logger, 'train', image_outputs, global_step)\n",
    "\n",
    "            del scalar_outputs\n",
    "            print(f'Epoch {epoch_idx + 1}/{args.epochs}, Iter {batch_idx + 1}/{len(TrainImgLoader)}, train loss = {loss:.3f}, time = {(time.time() - start_time):.3f}')\n",
    "        \n",
    "        # saving checkpoints\n",
    "        if (epoch_idx + 1) % args.save_freq == 0:\n",
    "            checkpoint_data = {'epoch': epoch_idx, 'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "            torch.save(checkpoint_data, f\"{args.logdir}/checkpoint_{epoch_idx:0>6}.ckpt\")\n",
    "        gc.collect()\n",
    "\n",
    "        # testing\n",
    "        avg_test_scalars = AverageMeterDict()\n",
    "        for batch_idx, sample in enumerate(TestImgLoader):\n",
    "            global_step = len(TestImgLoader) * epoch_idx + batch_idx\n",
    "            start_time = time.time()\n",
    "            do_summary = global_step % args.summary_freq == 0\n",
    "            loss, scalar_outputs = test_sample(sample, compute_metrics=do_summary)\n",
    "\n",
    "            # if do_summary:\n",
    "                # save_scalars(logger, 'test', scalar_outputs, global_step)\n",
    "                # save_images(logger, 'test', image_outputs, global_step)\n",
    "            \n",
    "            avg_test_scalars.update(scalar_outputs)\n",
    "            del scalar_outputs\n",
    "            print(f'Epoch {epoch_idx + 1}/{args.epochs}, Iter {batch_idx + 1}/{len(TestImgLoader)}, test loss = {loss:.3f}, time = {time.time() - start_time:3f}')\n",
    "\n",
    "        avg_test_scalars = avg_test_scalars.mean()\n",
    "        nowerror = avg_test_scalars[\"D1\"][0]\n",
    "\n",
    "        if  nowerror < error :\n",
    "            bestepoch = epoch_idx\n",
    "            error = avg_test_scalars[\"D1\"][0]\n",
    "\n",
    "        # save_scalars(logger, 'fulltest', avg_test_scalars, len(TrainImgLoader) * (epoch_idx + 1))\n",
    "        print(\"avg_test_scalars\", avg_test_scalars)\n",
    "        print('MAX epoch %d total test error = %.5f' % (bestepoch, error))\n",
    "        gc.collect()\n",
    "\n",
    "    print('MAX epoch %d total test error = %.5f' % (bestepoch, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downscale epochs: [10, 14, 16, 18], downscale rate: 2.0\n",
      "setting learning rate to 0.001\n",
      "Max disparity value: -1.125\n",
      "Min disparity value: -91.46875\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Empty mask, no True values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 189\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    187\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    188\u001b[0m do_summary \u001b[38;5;241m=\u001b[39m global_step \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39msummary_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 189\u001b[0m loss, scalar_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_summary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# if do_summary:\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# save_scalars(logger, 'train', scalar_outputs, global_step)\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# save_images(logger, 'train', image_outputs, global_step)\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m scalar_outputs\n",
      "Cell \u001b[1;32mIn[1], line 128\u001b[0m, in \u001b[0;36mtrain_sample\u001b[1;34m(sample, compute_metrics)\u001b[0m\n\u001b[0;32m    126\u001b[0m masks     \u001b[38;5;241m=\u001b[39m [mask, mask_low]\n\u001b[0;32m    127\u001b[0m disp_gts  \u001b[38;5;241m=\u001b[39m [disp_gt, disp_gt_low] \n\u001b[1;32m--> 128\u001b[0m loss      \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_loss_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisp_ests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp_gts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m scalar_outputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss}\n\u001b[0;32m    131\u001b[0m image_outputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp_est\u001b[39m\u001b[38;5;124m\"\u001b[39m: disp_ests, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp_gt\u001b[39m\u001b[38;5;124m\"\u001b[39m: disp_gt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgL\u001b[39m\u001b[38;5;124m\"\u001b[39m: imgL, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgR\u001b[39m\u001b[38;5;124m\"\u001b[39m: imgR}\n",
      "File \u001b[1;32mc:\\Users\\Askil\\iCloudDrive\\Data Science\\data_science\\spesiale\\data_science_speciale\\AsJo-Net\\models\\loss.py:13\u001b[0m, in \u001b[0;36mmodel_loss_train\u001b[1;34m(disp_ests, disp_gts, img_masks)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(disp_gt)\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN in disp_gt before mask\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Ensure masks are not entirely false\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mask_img\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty mask, no True values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Ensure masked tensors are not empty\u001b[39;00m\n\u001b[0;32m     16\u001b[0m masked_disp_est \u001b[38;5;241m=\u001b[39m disp_est[mask_img]\n",
      "\u001b[1;31mAssertionError\u001b[0m: Empty mask, no True values"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_iter = iter(TestImgLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(image_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(image['left'][0].unsqueeze(0).cuda(), image['right'][0].unsqueeze(0).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tensors(left, right, disp):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "    ax[0].imshow(left.numpy().transpose(1, 2, 0))\n",
    "    ax[0].set_title('Left Image')\n",
    "    ax[1].imshow(disp.cpu().detach().squeeze(0).numpy())\n",
    "    ax[1].set_title('Disparity')\n",
    "    ax[2].imshow(right.numpy().transpose(1, 2, 0))\n",
    "    ax[2].set_title('Right Image')\n",
    "    plt.show()\n",
    "\n",
    "# plot_tensors(image['left'][0], image['right'][0], image['disparity'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the tensor and ensuring it's on CPU\n",
    "tensor_gray = output[0].cpu().detach().squeeze(0).numpy()  # Removing channel dim\n",
    "\n",
    "# Converting to numpy\n",
    "image_gray = tensor_gray\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_gray, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Grayscale Image')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speciale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
